import streamlit as st
import pandas as pd
from database.db import create_table, clear_table
from scrapers.selenium_scraper import scrape_category_selenium
import os

# Cr√©ation DB si n√©cessaire
os.makedirs("database", exist_ok=True)
create_table()

# -----------------------------
# SIDEBAR
# -----------------------------
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/616/616408.png", width=100)
    st.title("Bienvenue !")
    st.write("Bienvenue sur l'application de scraping CoinAfrique üê∂üêëüêì")

    st.markdown("---")
    index_value = st.selectbox("Nombre de pages √† scrapers", list(range(1, 101)))
    menu_option = st.selectbox(
        "Menu",
        [
            "Scraper en utilisant BeautifulSoup",
            "Scraper en utilisant Selenium",
            "T√©l√©charger des donn√©es d√©j√† scrap√©es (Web Scraper) (√† venir)",
            "Voir dashboard des donn√©es",
            "Formulaire d'evaluation de l'application"
        ]
    )

# -----------------------------
# CONTENU PRINCIPAL
# -----------------------------
st.markdown(
    """
    <h1 style='text-align: center; margin-top: 50px;'>Application de scraping CoinAfrique üê∂üêëüêì</h1>
    """,
    unsafe_allow_html=True
)

# Initialiser l'√©tat si pas d√©fini
if "scraping" not in st.session_state:
    st.session_state.scraping = False

# -----------------------------
# SCRAPING SELON MENU
# -----------------------------
if menu_option == "Scraper en utilisant Selenium":
    st.info(f"Scraping {index_value} page(s) avec Selenium")

    # Bouton unique
    if st.button("Lancer le scraping") and not st.session_state.scraping:
        st.session_state.scraping = True
        status_placeholder = st.empty()
        status_placeholder.markdown("**Scraping en cours, veuillez patienter ...**")

        # Vider la table avant nouveau scraping
        clear_table()

        categories = {
            "Chiens": "https://sn.coinafrique.com/categorie/chiens",
            "Moutons": "https://sn.coinafrique.com/categorie/moutons",
            "Poules / Lapins / Pigeons": "https://sn.coinafrique.com/categorie/poules-lapins-et-pigeons",
            "Autres animaux": "https://sn.coinafrique.com/categorie/autres-animaux"
        }

        all_data = {}
        progress_bar = st.progress(0)

        # Scraper chaque cat√©gorie
        with st.spinner("Scraping en cours, veuillez patienter ..."):
            for i, (cat, url) in enumerate(categories.items(), 1):
                data = scrape_category_selenium(cat, url, max_pages=index_value)
                all_data[cat] = data
                progress_bar.progress(i / len(categories))

        st.success("Scraping termin√© et donn√©es sauvegard√©es !")

        # Afficher les r√©sultats
        for cat, data in all_data.items():
            st.subheader(cat)
            if data:
                df = pd.DataFrame(data)
                st.caption(f"Dataset : {len(df):,} lignes x {df.shape[1]} colonnes")
                st.dataframe(df)
            else:
                st.caption("Dataset : 0 lignes x 0 colonnes")
                st.write("Aucune donn√©e trouv√©e pour cette cat√©gorie.")

        # R√©initialiser le statut pour pouvoir relancer
        st.session_state.scraping = False
        status_placeholder.empty()

# -----------------------------
# OPTION BEAUTIFULSOUP (inchang√©e)
# -----------------------------
elif menu_option == "Scraper en utilisant BeautifulSoup":
    st.info(f"Scraping {index_value} page(s) avec BeautifulSoup")

    if st.button("Lancer le scraping") and not st.session_state.scraping:
        st.session_state.scraping = True
        status_placeholder = st.empty()
        status_placeholder.markdown("**Scraping en cours, veuillez patienter ...**")

        clear_table()

        categories = {
            "Chiens": "https://sn.coinafrique.com/categorie/chiens",
            "Moutons": "https://sn.coinafrique.com/categorie/moutons",
            "Poules / Lapins / Pigeons": "https://sn.coinafrique.com/categorie/poules-lapins-et-pigeons",
            "Autres animaux": "https://sn.coinafrique.com/categorie/autres-animaux"
        }

        all_data = {}
        progress_bar = st.progress(0)

        with st.spinner("Scraping en cours, veuillez patienter ..."):
            for i, (cat, url) in enumerate(categories.items(), 1):
                from scrapers.beautifulsoup_scraper import scrape_category
                data = scrape_category(cat, url, max_pages=index_value)
                all_data[cat] = data
                progress_bar.progress(i / len(categories))

        st.success("Scraping termin√© et donn√©es sauvegard√©es !")

        for cat, data in all_data.items():
            st.subheader(cat)
            if data:
                df = pd.DataFrame(data)
                st.caption(f"Dataset : {len(df):,} lignes x {df.shape[1]} colonnes")
                st.dataframe(df)
            else:
                st.caption("Dataset : 0 lignes x 0 colonnes")
                st.write("Aucune donn√©e trouv√©e pour cette cat√©gorie.")

        st.session_state.scraping = False
        status_placeholder.empty()
# -----------------------------
# AFFICHER TOUS LES CSV EXISTANTS
# -----------------------------
elif menu_option == "T√©l√©charger des donn√©es d√©j√† scrap√©es (Web Scraper) (√† venir)":
    # Banni√®re et description
    st.markdown("<h1 style='text-align: center; color: #2F4F4F;'>Donn√©es d√©j√† scrap√©es üóÇÔ∏è</h1>", unsafe_allow_html=True)
    st.markdown("<h3 style='text-align: center; color: #555;'>Vous pouvez consulter les donn√©es collect√©es automatiquement ou via Web Scraper par cat√©gorie et les t√©l√©charg√©es.</h3>", unsafe_allow_html=True)
    st.markdown("---")

    # Mapping des fichiers vers le label que tu veux afficher
    csv_folder = "csv_data"
    csv_labels = {
        "chiens.csv": "Chiens üê∂",
        "moutons.csv": "Moutons üêë",
        "pigeonslapins.csv": "Poules, Lapins et Pigeons üê¶üêá",
        "autres.csv": "Autres animaux üêìüêñ"
    }

    for file, label in csv_labels.items():
        csv_path = os.path.join(csv_folder, file)
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path)
            st.subheader(label)
            st.caption(f"Dataset : {len(df):,} lignes x {df.shape[1]} colonnes")
            st.dataframe(df)
        else:
            st.warning(f"Le fichier {file} est introuvable dans {csv_folder}/")

elif menu_option == "Voir dashboard des donn√©es":
    import importlib
    import dashboard
    importlib.reload(dashboard)

elif menu_option == "Formulaire d'evaluation de l'application":

    st.markdown(
        """
        <h1 style='text-align: center; color: #2F4F4F;'>
        üìù Formulaire d‚Äô√©valuation de l‚Äôapplication
        </h1>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <p style='text-align: center; font-size:18px;'>
        Merci de prendre quelques minutes pour √©valuer l'application.
        </p>
        """,
        unsafe_allow_html=True
    )

    # Int√©gration du formulaire Kobo
    st.components.v1.iframe(
        "https://ee.kobotoolbox.org/9WG74Oku",
        height=800,
        scrolling=True
    )